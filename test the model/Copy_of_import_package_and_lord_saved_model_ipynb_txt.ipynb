{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f16edf3e",
      "metadata": {
        "id": "f16edf3e"
      },
      "source": [
        "\n",
        "# Real-Time Communication System Powered By AI For Specially Abled\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef959492",
      "metadata": {
        "id": "ef959492"
      },
      "source": [
        "# TEAM ID - 2022TMID52086"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "497df092",
      "metadata": {
        "id": "497df092"
      },
      "source": [
        "Image Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10787c6b",
      "metadata": {
        "id": "10787c6b"
      },
      "source": [
        "Import ImageDataGenerator Library And Configure It"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33ac33a4",
      "metadata": {
        "id": "33ac33a4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89cedbc3",
      "metadata": {
        "id": "89cedbc3"
      },
      "outputs": [],
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,horizontal_flip=True,vertical_flip=True,zoom_range=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db2935ad",
      "metadata": {
        "id": "db2935ad"
      },
      "outputs": [],
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76090c73",
      "metadata": {
        "id": "76090c73"
      },
      "source": [
        "Apply ImageDataGenerator Functionality To Train And Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75815293",
      "metadata": {
        "id": "75815293",
        "outputId": "e596f8c3-e929-4d6b-eb6f-e11d529d32e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 15750 images belonging to 9 classes.\n"
          ]
        }
      ],
      "source": [
        "x_train=train_datagen.flow_from_directory(r\"C:\\Users\\rajes\\Desktop\\Dataset\\training_set\",target_size=(64,64),\n",
        "                                          class_mode=\"categorical\",batch_size=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8a773a8",
      "metadata": {
        "id": "c8a773a8",
        "outputId": "47b7cc18-772e-426d-b407-a7847b19b00e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2250 images belonging to 9 classes.\n"
          ]
        }
      ],
      "source": [
        "x_test=test_datagen.flow_from_directory(r\"C:\\Users\\rajes\\Desktop\\Dataset\\test_set\",target_size=(64,64),\n",
        "                                                            class_mode=\"categorical\",batch_size=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b7d8e26",
      "metadata": {
        "id": "1b7d8e26"
      },
      "source": [
        "Model  Building\n",
        "\n",
        "Import The Required Model Building Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06b0e403",
      "metadata": {
        "id": "06b0e403"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1184364",
      "metadata": {
        "id": "c1184364"
      },
      "source": [
        "Initialize The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c96b11c1",
      "metadata": {
        "id": "c96b11c1",
        "outputId": "e6d39da5-6379-4354-ef3c-ae9a3a6ca11b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Initialized Successfully\n"
          ]
        }
      ],
      "source": [
        "model=Sequential()\n",
        "print(\"Model Initialized Successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c86cd76",
      "metadata": {
        "id": "2c86cd76"
      },
      "source": [
        "Add The Convolution Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffda151f",
      "metadata": {
        "id": "ffda151f"
      },
      "outputs": [],
      "source": [
        "model.add(Convolution2D(32,(3,3),activation=\"relu\",input_shape=(64,64,3)))\n",
        "#No of feature detectors, size of feature detector, image size, activation function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59237fe1",
      "metadata": {
        "id": "59237fe1"
      },
      "source": [
        "Add The Pooling Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51eb3e8c",
      "metadata": {
        "id": "51eb3e8c"
      },
      "outputs": [],
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbaf6f7d",
      "metadata": {
        "id": "cbaf6f7d"
      },
      "source": [
        "Add The Flatten Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b72c2364",
      "metadata": {
        "id": "b72c2364"
      },
      "outputs": [],
      "source": [
        "model.add(Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b20ccef",
      "metadata": {
        "id": "4b20ccef"
      },
      "source": [
        "Adding The Dense Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acf8a03c",
      "metadata": {
        "id": "acf8a03c"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(500,activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ac2c154",
      "metadata": {
        "id": "1ac2c154"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(300,activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9f1bc8e",
      "metadata": {
        "id": "a9f1bc8e"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(9,activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de4e3fcb",
      "metadata": {
        "id": "de4e3fcb"
      },
      "source": [
        "Compile The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e86c2425",
      "metadata": {
        "id": "e86c2425"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",metrics=[\"accuracy\"],optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "090d77ef",
      "metadata": {
        "id": "090d77ef",
        "outputId": "d1fa27f4-2fb7-415f-e1aa-37009084a2fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "525"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26760e58",
      "metadata": {
        "id": "26760e58",
        "outputId": "202d95d2-2384-46d0-d079-ecfd235be6bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "75"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "900ea430",
      "metadata": {
        "id": "900ea430",
        "outputId": "e07390b9-e9df-4bd9-9001-141d84865b2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "751be546",
      "metadata": {
        "id": "751be546"
      },
      "source": [
        "Fit And Save The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d8c0db8",
      "metadata": {
        "id": "8d8c0db8",
        "outputId": "b1e985a3-2b1a-4146-84cf-8b8b9f2e8895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "525/525 [==============================] - 620s 1s/step - loss: 0.6116 - accuracy: 0.7691 - val_loss: 0.3006 - val_accuracy: 0.9329\n",
            "Epoch 2/8\n",
            "525/525 [==============================] - 223s 425ms/step - loss: 0.1041 - accuracy: 0.9683 - val_loss: 0.0779 - val_accuracy: 0.9858\n",
            "Epoch 3/8\n",
            "525/525 [==============================] - 132s 250ms/step - loss: 0.0592 - accuracy: 0.9829 - val_loss: 0.1236 - val_accuracy: 0.9760\n",
            "Epoch 4/8\n",
            "525/525 [==============================] - 104s 198ms/step - loss: 0.0431 - accuracy: 0.9879 - val_loss: 0.2067 - val_accuracy: 0.9742\n",
            "Epoch 5/8\n",
            "525/525 [==============================] - 107s 204ms/step - loss: 0.0322 - accuracy: 0.9912 - val_loss: 0.0713 - val_accuracy: 0.9800\n",
            "Epoch 6/8\n",
            "525/525 [==============================] - 113s 216ms/step - loss: 0.0348 - accuracy: 0.9895 - val_loss: 0.1267 - val_accuracy: 0.9787\n",
            "Epoch 7/8\n",
            "525/525 [==============================] - 101s 193ms/step - loss: 0.0293 - accuracy: 0.9926 - val_loss: 0.1558 - val_accuracy: 0.9751\n",
            "Epoch 8/8\n",
            "525/525 [==============================] - 107s 205ms/step - loss: 0.0222 - accuracy: 0.9940 - val_loss: 0.1998 - val_accuracy: 0.9769\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x20f394a4e20>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train,epochs=8,validation_data=x_test,steps_per_epoch=len(x_train),validation_steps=len(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd3d001b",
      "metadata": {
        "id": "bd3d001b"
      },
      "outputs": [],
      "source": [
        "model.save(\"C:/Users/rajes/Downloads/signlanguage-new.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14ba340c",
      "metadata": {
        "id": "14ba340c"
      },
      "source": [
        "Test the Model\n",
        "\n",
        "Import The Packages And Load The Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c47dfac",
      "metadata": {
        "id": "9c47dfac"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import h5py\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32e9bdba",
      "metadata": {
        "id": "32e9bdba"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image \n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67feadff",
      "metadata": {
        "id": "67feadff"
      },
      "outputs": [],
      "source": [
        "model = load_model(\"C:/Users/rajes/Downloads/signlanguage-new.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "139ba7da",
      "metadata": {
        "id": "139ba7da"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}