{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f16edf3e",
      "metadata": {
        "id": "f16edf3e"
      },
      "source": [
        "\n",
        "# Real-Time Communication System Powered By AI For Specially Abled\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef959492",
      "metadata": {
        "id": "ef959492"
      },
      "source": [
        "# TEAM ID - 2022TMID52086"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "497df092",
      "metadata": {
        "id": "497df092"
      },
      "source": [
        "Image Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10787c6b",
      "metadata": {
        "id": "10787c6b"
      },
      "source": [
        "Import ImageDataGenerator Library And Configure It"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33ac33a4",
      "metadata": {
        "id": "33ac33a4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89cedbc3",
      "metadata": {
        "id": "89cedbc3"
      },
      "outputs": [],
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,horizontal_flip=True,vertical_flip=True,zoom_range=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db2935ad",
      "metadata": {
        "id": "db2935ad"
      },
      "outputs": [],
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76090c73",
      "metadata": {
        "id": "76090c73"
      },
      "source": [
        "Apply ImageDataGenerator Functionality To Train And Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b667b67",
      "metadata": {
        "id": "6b667b67",
        "outputId": "258f3eb5-736c-4fbe-f2de-2218a3da8f61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 15750 images belonging to 9 classes.\n"
          ]
        }
      ],
      "source": [
        "x_train=train_datagen.flow_from_directory(r\"C:\\Users\\rajes\\Desktop\\Dataset\\training_set\",target_size=(64,64),\n",
        "                                          class_mode=\"categorical\",batch_size=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "098ab542",
      "metadata": {
        "id": "098ab542",
        "outputId": "e01bd0cd-577f-4d44-88c6-a0359dbde8e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2250 images belonging to 9 classes.\n"
          ]
        }
      ],
      "source": [
        "x_test=test_datagen.flow_from_directory(r\"C:\\Users\\rajes\\Desktop\\Dataset\\test_set\",target_size=(64,64),\n",
        "                                                            class_mode=\"categorical\",batch_size=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b038d6d8",
      "metadata": {
        "id": "b038d6d8"
      },
      "source": [
        "Model  Building\n",
        "\n",
        "Import The Required Model Building Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31d9cac4",
      "metadata": {
        "id": "31d9cac4"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e2b0256",
      "metadata": {
        "id": "5e2b0256"
      },
      "source": [
        "Initialize The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "791b6ebb",
      "metadata": {
        "id": "791b6ebb",
        "outputId": "40f59961-9ae2-4dbc-9774-704ee51ecc74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Initialized Successfully\n"
          ]
        }
      ],
      "source": [
        "model=Sequential()\n",
        "print(\"Model Initialized Successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c32bcf0",
      "metadata": {
        "id": "2c32bcf0"
      },
      "source": [
        "Add The Convolution Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2724b142",
      "metadata": {
        "id": "2724b142"
      },
      "outputs": [],
      "source": [
        "model.add(Convolution2D(32,(3,3),activation=\"relu\",input_shape=(64,64,3)))\n",
        "#No of feature detectors, size of feature detector, image size, activation function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ca25294",
      "metadata": {
        "id": "6ca25294"
      },
      "source": [
        "Add The Pooling Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a5771b8",
      "metadata": {
        "id": "0a5771b8"
      },
      "outputs": [],
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0efa72e8",
      "metadata": {
        "id": "0efa72e8"
      },
      "source": [
        "Add The Flatten Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d355a674",
      "metadata": {
        "id": "d355a674"
      },
      "outputs": [],
      "source": [
        "model.add(Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "317f5e76",
      "metadata": {
        "id": "317f5e76"
      },
      "source": [
        "Adding The Dense Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56b59b7e",
      "metadata": {
        "id": "56b59b7e"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(500,activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "204f7482",
      "metadata": {
        "id": "204f7482"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(300,activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f96b2ea0",
      "metadata": {
        "id": "f96b2ea0"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(9,activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "274341d1",
      "metadata": {
        "id": "274341d1"
      },
      "source": [
        "Compile The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20852f8c",
      "metadata": {
        "id": "20852f8c"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",metrics=[\"accuracy\"],optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12c28cc2",
      "metadata": {
        "id": "12c28cc2",
        "outputId": "e97e6c00-7b65-4f94-d113-2be373d743cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "525"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b7a0abc",
      "metadata": {
        "id": "9b7a0abc",
        "outputId": "84b22c14-3312-474e-b79c-991b72fbf017"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "75"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31272f00",
      "metadata": {
        "id": "31272f00",
        "outputId": "c60f7bee-db30-46ab-be70-fe9e86babe31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb393c85",
      "metadata": {
        "id": "eb393c85"
      },
      "source": [
        "Fit And Save The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c45c08fa",
      "metadata": {
        "id": "c45c08fa",
        "outputId": "7bf0f67a-9298-4016-98d5-3d717b24ebff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "525/525 [==============================] - 620s 1s/step - loss: 0.6116 - accuracy: 0.7691 - val_loss: 0.3006 - val_accuracy: 0.9329\n",
            "Epoch 2/8\n",
            "525/525 [==============================] - 223s 425ms/step - loss: 0.1041 - accuracy: 0.9683 - val_loss: 0.0779 - val_accuracy: 0.9858\n",
            "Epoch 3/8\n",
            "525/525 [==============================] - 132s 250ms/step - loss: 0.0592 - accuracy: 0.9829 - val_loss: 0.1236 - val_accuracy: 0.9760\n",
            "Epoch 4/8\n",
            "525/525 [==============================] - 104s 198ms/step - loss: 0.0431 - accuracy: 0.9879 - val_loss: 0.2067 - val_accuracy: 0.9742\n",
            "Epoch 5/8\n",
            "525/525 [==============================] - 107s 204ms/step - loss: 0.0322 - accuracy: 0.9912 - val_loss: 0.0713 - val_accuracy: 0.9800\n",
            "Epoch 6/8\n",
            "525/525 [==============================] - 113s 216ms/step - loss: 0.0348 - accuracy: 0.9895 - val_loss: 0.1267 - val_accuracy: 0.9787\n",
            "Epoch 7/8\n",
            "525/525 [==============================] - 101s 193ms/step - loss: 0.0293 - accuracy: 0.9926 - val_loss: 0.1558 - val_accuracy: 0.9751\n",
            "Epoch 8/8\n",
            "525/525 [==============================] - 107s 205ms/step - loss: 0.0222 - accuracy: 0.9940 - val_loss: 0.1998 - val_accuracy: 0.9769\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x20f394a4e20>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train,epochs=8,validation_data=x_test,steps_per_epoch=len(x_train),validation_steps=len(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f9129d2",
      "metadata": {
        "id": "4f9129d2"
      },
      "outputs": [],
      "source": [
        "model.save(\"C:/Users/rajes/Downloads/signlanguage-new.h5\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}